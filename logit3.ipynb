{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7a121f6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lixiaozao/opt/anaconda3/lib/python3.9/site-packages/transformers/utils/generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "/Users/lixiaozao/opt/anaconda3/lib/python3.9/site-packages/transformers/utils/generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/Users/lixiaozao/opt/anaconda3/lib/python3.9/site-packages/transformers/utils/generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9d731dbb7ae41d3ba9cc7b322756a33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "# Set your token and load the tokenizer and model\n",
    "token = \"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\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Meta-Llama-3-8B\", token=token)\n",
    "model = AutoModelForCausalLM.from_pretrained(\"meta-llama/Meta-Llama-3-8B\", token=token)\n",
    "\n",
    "# Dictionary to store activations\n",
    "activations = {}\n",
    "\n",
    "# Hook function to capture activations\n",
    "def get_activation_hook(name):\n",
    "    def hook(model, input, output):\n",
    "        activations[name] = output.detach()\n",
    "    return hook\n",
    "\n",
    "# Register hooks for all layers in the model\n",
    "for i, layer in enumerate(model.model.layers):\n",
    "    layer.mlp.register_forward_hook(get_activation_hook(f'layer_{i}_mlp'))\n",
    "\n",
    "# Encode input text\n",
    "input_ids = tokenizer.encode(\"The quick brown fox jumps over the lazy dog\", return_tensors=\"pt\")\n",
    "\n",
    "# Forward pass to collect activations\n",
    "outputs = model(input_ids)\n",
    "\n",
    "# Now activations dictionary contains outputs for all layers\n",
    "final_logits = outputs.logits.squeeze(0)  # Remove batch dimension if necessary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a63e02a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Initialize lists to store losses\n",
    "cross_entropy_losses = []\n",
    "kl_divergences = []\n",
    "\n",
    "# Linear layer to match hidden size to vocabulary size\n",
    "hidden_size = activations['layer_0_mlp'].size(-1)\n",
    "vocab_size = final_logits.size(-1)\n",
    "linear_projection = nn.Linear(hidden_size, vocab_size).to(final_logits.device)\n",
    "\n",
    "# Cross-Entropy Loss calculation\n",
    "for i in range(32):\n",
    "    layer_logits = activations[f'layer_{i}_mlp']\n",
    "    \n",
    "    # Project layer logits to match the final logits shape\n",
    "    projected_logits = linear_projection(layer_logits)\n",
    "    \n",
    "    # Reshape to match the final logits for cross-entropy computation\n",
    "    projected_logits = projected_logits.view(-1, vocab_size)\n",
    "    final_logits_reshaped = final_logits.view(-1, vocab_size)\n",
    "    \n",
    "    # Compute Cross-Entropy\n",
    "    loss = F.cross_entropy(projected_logits, final_logits_reshaped.argmax(dim=-1))\n",
    "    cross_entropy_losses.append(loss.item())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e4b533e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[11.757238388061523,\n",
       " 12.334437370300293,\n",
       " 11.759215354919434,\n",
       " 11.75847339630127,\n",
       " 11.755319595336914,\n",
       " 11.753714561462402,\n",
       " 11.74796199798584,\n",
       " 11.754512786865234,\n",
       " 11.765863418579102,\n",
       " 11.759199142456055,\n",
       " 11.74631404876709,\n",
       " 11.756658554077148,\n",
       " 11.745182037353516,\n",
       " 11.75864028930664,\n",
       " 11.773157119750977,\n",
       " 11.746389389038086,\n",
       " 11.761775016784668,\n",
       " 11.753610610961914,\n",
       " 11.762552261352539,\n",
       " 11.76201057434082,\n",
       " 11.760408401489258,\n",
       " 11.764768600463867,\n",
       " 11.766378402709961,\n",
       " 11.740522384643555,\n",
       " 11.764920234680176,\n",
       " 11.754125595092773,\n",
       " 11.767090797424316,\n",
       " 11.744226455688477,\n",
       " 11.720169067382812,\n",
       " 11.788668632507324,\n",
       " 11.8467435836792,\n",
       " 12.33767318725586]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_entropy_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4bcd63e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# KL Divergence calculation\n",
    "for i in range(31):\n",
    "    for j in range(i + 1, 32):\n",
    "        logits_i = activations[f'layer_{i}_mlp']\n",
    "        logits_j = activations[f'layer_{j}_mlp']\n",
    "        \n",
    "        # Project logits to match the final logits shape\n",
    "        projected_logits_i = linear_projection(logits_i)\n",
    "        projected_logits_j = linear_projection(logits_j)\n",
    "\n",
    "        # Calculate KL divergence\n",
    "        kl_div = F.kl_div(F.log_softmax(projected_logits_i.view(-1, vocab_size), dim=-1), \n",
    "                          F.softmax(projected_logits_j.view(-1, vocab_size), dim=-1), \n",
    "                          reduction='batchmean')\n",
    "        kl_divergences.append(kl_div.item())\n",
    "\n",
    "# At this point, cross_entropy_losses and kl_divergences contain the computed values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ec972b0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.2729949355125427,\n",
       " 0.00041331740794703364,\n",
       " 0.0004601589753292501,\n",
       " 0.0004984528059139848,\n",
       " 0.0005551259382627904,\n",
       " 0.0006257999921217561,\n",
       " 0.0006501491297967732,\n",
       " 0.0006165402010083199,\n",
       " 0.000642703496851027,\n",
       " 0.0006624135421589017,\n",
       " 0.0006623633671551943,\n",
       " 0.0006383726140484214,\n",
       " 0.0006809426704421639,\n",
       " 0.0007675110828131437,\n",
       " 0.0008893537451513112,\n",
       " 0.0009327458101324737,\n",
       " 0.001047943951562047,\n",
       " 0.0011063308920711279,\n",
       " 0.0015609966358169913,\n",
       " 0.0011360043426975608,\n",
       " 0.001256003975868225,\n",
       " 0.0012442891020327806,\n",
       " 0.0013011537957936525,\n",
       " 0.0014935277868062258,\n",
       " 0.001790632144547999,\n",
       " 0.0019352470990270376,\n",
       " 0.002514322753995657,\n",
       " 0.003335612593218684,\n",
       " 0.005038512870669365,\n",
       " 0.012732106260955334,\n",
       " 0.4368975758552551,\n",
       " 0.42961254715919495,\n",
       " 0.42959871888160706,\n",
       " 0.4296061098575592,\n",
       " 0.4296080470085144,\n",
       " 0.4297683835029602,\n",
       " 0.4298507571220398,\n",
       " 0.4298326373100281,\n",
       " 0.42995819449424744,\n",
       " 0.4251581132411957,\n",
       " 0.43000832200050354,\n",
       " 0.4298298954963684,\n",
       " 0.42987555265426636,\n",
       " 0.4300379753112793,\n",
       " 0.43031397461891174,\n",
       " 0.4300615191459656,\n",
       " 0.4299805760383606,\n",
       " 0.4304250180721283,\n",
       " 0.43093496561050415,\n",
       " 0.43066635727882385,\n",
       " 0.4306116998195648,\n",
       " 0.4307178854942322,\n",
       " 0.4307801127433777,\n",
       " 0.43104100227355957,\n",
       " 0.4313720762729645,\n",
       " 0.4314557909965515,\n",
       " 0.43289676308631897,\n",
       " 0.43334048986434937,\n",
       " 0.4361198842525482,\n",
       " 0.4464693069458008,\n",
       " 1.5751889944076538,\n",
       " 0.00013784566544927657,\n",
       " 0.00018070326768793166,\n",
       " 0.00023073579359333962,\n",
       " 0.00029597297543659806,\n",
       " 0.00032176863169297576,\n",
       " 0.00029387857648544014,\n",
       " 0.0003192088915966451,\n",
       " 0.00033036377863027155,\n",
       " 0.00033178491867147386,\n",
       " 0.00031382625456899405,\n",
       " 0.0003572067362256348,\n",
       " 0.00044840312330052257,\n",
       " 0.0005652125691995025,\n",
       " 0.000606236164458096,\n",
       " 0.0007234481745399535,\n",
       " 0.000773677951656282,\n",
       " 0.0012361947447061539,\n",
       " 0.0008117128163576126,\n",
       " 0.0009299231460317969,\n",
       " 0.0009243605891242623,\n",
       " 0.0009738150984048843,\n",
       " 0.0011745213996618986,\n",
       " 0.0014646562049165368,\n",
       " 0.0016215738141909242,\n",
       " 0.0021924604661762714,\n",
       " 0.0030232067219913006,\n",
       " 0.0048338002525269985,\n",
       " 0.01253710687160492,\n",
       " 0.43609386682510376,\n",
       " 0.00023591596982441843,\n",
       " 0.00027480366406962276,\n",
       " 0.0003426664334256202,\n",
       " 0.00036316565820015967,\n",
       " 0.0003311038308311254,\n",
       " 0.0003581469354685396,\n",
       " 0.00037310997140593827,\n",
       " 0.00037872110260650516,\n",
       " 0.0003572061541490257,\n",
       " 0.0003972250851802528,\n",
       " 0.0004905688692815602,\n",
       " 0.0006104817730374634,\n",
       " 0.0006462264573201537,\n",
       " 0.0007697374676354229,\n",
       " 0.0008193613030016422,\n",
       " 0.0012864393647760153,\n",
       " 0.0008581826696172357,\n",
       " 0.0009775826474651694,\n",
       " 0.0009700910886749625,\n",
       " 0.0010165749117732048,\n",
       " 0.0012139180907979608,\n",
       " 0.0015090734232217073,\n",
       " 0.0016679682303220034,\n",
       " 0.002240485744550824,\n",
       " 0.003066397737711668,\n",
       " 0.0048736827448010445,\n",
       " 0.012585325166583061,\n",
       " 0.43608206510543823,\n",
       " 0.00031766208121553063,\n",
       " 0.0003692942555062473,\n",
       " 0.0004092047456651926,\n",
       " 0.00036101246951147914,\n",
       " 0.00039072963409125805,\n",
       " 0.00040444411570206285,\n",
       " 0.00041481730295345187,\n",
       " 0.00039435154758393764,\n",
       " 0.0004324511101003736,\n",
       " 0.0005286542582325637,\n",
       " 0.000648131943307817,\n",
       " 0.0006847431650385261,\n",
       " 0.0008137646364048123,\n",
       " 0.0008721976773813367,\n",
       " 0.001318400027230382,\n",
       " 0.0008964227745309472,\n",
       " 0.001020508585497737,\n",
       " 0.0010072060395032167,\n",
       " 0.0010622170520946383,\n",
       " 0.0012573854764923453,\n",
       " 0.0015601746272295713,\n",
       " 0.0016832284163683653,\n",
       " 0.002279622945934534,\n",
       " 0.0031048052478581667,\n",
       " 0.004906965885311365,\n",
       " 0.012618805281817913,\n",
       " 0.4362258315086365,\n",
       " 0.00045151947415433824,\n",
       " 0.00046626394032500684,\n",
       " 0.00042097788536921144,\n",
       " 0.0004436546878423542,\n",
       " 0.00045963856973685324,\n",
       " 0.0004765045887324959,\n",
       " 0.00044825198710896075,\n",
       " 0.0004818472662009299,\n",
       " 0.000580146792344749,\n",
       " 0.0006984150386415422,\n",
       " 0.0007334886468015611,\n",
       " 0.0008667820366099477,\n",
       " 0.0009188220137730241,\n",
       " 0.0013538862112909555,\n",
       " 0.000946708838455379,\n",
       " 0.0010759999277070165,\n",
       " 0.0010557350469753146,\n",
       " 0.0011059551034122705,\n",
       " 0.0013018231838941574,\n",
       " 0.001603547716513276,\n",
       " 0.0017344718798995018,\n",
       " 0.002320959698408842,\n",
       " 0.0031634855549782515,\n",
       " 0.004962229635566473,\n",
       " 0.012661302462220192,\n",
       " 0.43643003702163696,\n",
       " 0.0005590012879110873,\n",
       " 0.0004937339690513909,\n",
       " 0.0005268073873594403,\n",
       " 0.0005367210251279175,\n",
       " 0.0005239371675997972,\n",
       " 0.0005289954715408385,\n",
       " 0.000564195157494396,\n",
       " 0.0006746132858097553,\n",
       " 0.000787162221968174,\n",
       " 0.000819144188426435,\n",
       " 0.0009428132325410843,\n",
       " 0.0009796167723834515,\n",
       " 0.0014514268841594458,\n",
       " 0.0010158850345760584,\n",
       " 0.001132554141804576,\n",
       " 0.00113012851215899,\n",
       " 0.0011723418720066547,\n",
       " 0.0013754975516349077,\n",
       " 0.0016500266501680017,\n",
       " 0.001824870123527944,\n",
       " 0.0023975507356226444,\n",
       " 0.0032326311338692904,\n",
       " 0.0050478745251894,\n",
       " 0.012757934629917145,\n",
       " 0.4363929331302643,\n",
       " 0.00053582270629704,\n",
       " 0.0005474869976751506,\n",
       " 0.000562200671993196,\n",
       " 0.000553647056221962,\n",
       " 0.0005332999862730503,\n",
       " 0.0005837110220454633,\n",
       " 0.0006799465627409518,\n",
       " 0.0007911477005109191,\n",
       " 0.000832769088447094,\n",
       " 0.000953149632550776,\n",
       " 0.0010080661159008741,\n",
       " 0.0014691401738673449,\n",
       " 0.0010421157348901033,\n",
       " 0.0011517812963575125,\n",
       " 0.0011438460787758231,\n",
       " 0.001199962804093957,\n",
       " 0.0013875241857022047,\n",
       " 0.0016812824178487062,\n",
       " 0.0018391417106613517,\n",
       " 0.0024112930987030268,\n",
       " 0.0032549265306442976,\n",
       " 0.005049900151789188,\n",
       " 0.0128242839127779,\n",
       " 0.4366142153739929,\n",
       " 0.0005032176850363612,\n",
       " 0.0004989036242477596,\n",
       " 0.0005304759251885116,\n",
       " 0.0004926341352984309,\n",
       " 0.0005308267427608371,\n",
       " 0.0006268653669394553,\n",
       " 0.0007525861728936434,\n",
       " 0.0007901645149104297,\n",
       " 0.0009318970260210335,\n",
       " 0.0009892000816762447,\n",
       " 0.0014354472514241934,\n",
       " 0.001005844445899129,\n",
       " 0.0011527996975928545,\n",
       " 0.0011166654294356704,\n",
       " 0.0011756500462070107,\n",
       " 0.0013513464946299791,\n",
       " 0.0016508323606103659,\n",
       " 0.0018072111997753382,\n",
       " 0.0023855133913457394,\n",
       " 0.0032328448724001646,\n",
       " 0.005008316598832607,\n",
       " 0.012760473415255547,\n",
       " 0.43615251779556274,\n",
       " 0.0005634305998682976,\n",
       " 0.0005791873554699123,\n",
       " 0.0005257949233055115,\n",
       " 0.0005587997147813439,\n",
       " 0.0006572003476321697,\n",
       " 0.0007764439797028899,\n",
       " 0.0008131230133585632,\n",
       " 0.0009405313176102936,\n",
       " 0.001028020866215229,\n",
       " 0.0014546785969287157,\n",
       " 0.0010412067640572786,\n",
       " 0.0011711909901350737,\n",
       " 0.00113194203004241,\n",
       " 0.0011975925881415606,\n",
       " 0.0013928416883572936,\n",
       " 0.001664636074565351,\n",
       " 0.0018287969287484884,\n",
       " 0.0024072672240436077,\n",
       " 0.003251927439123392,\n",
       " 0.005031755194067955,\n",
       " 0.01280726958066225,\n",
       " 0.43622198700904846,\n",
       " 0.0005924708675593138,\n",
       " 0.0005411509773693979,\n",
       " 0.0005756180617026985,\n",
       " 0.0006690735463052988,\n",
       " 0.0008006056887097657,\n",
       " 0.0008390055154450238,\n",
       " 0.000976853771135211,\n",
       " 0.001023177755996585,\n",
       " 0.0014661557506769896,\n",
       " 0.0010526350233703852,\n",
       " 0.0011812221491709352,\n",
       " 0.0011566753964871168,\n",
       " 0.001214176299981773,\n",
       " 0.0013905910309404135,\n",
       " 0.00169264932628721,\n",
       " 0.0018315591150894761,\n",
       " 0.0024340697564184666,\n",
       " 0.0032708582002669573,\n",
       " 0.0050772749818861485,\n",
       " 0.012869136407971382,\n",
       " 0.4393898546695709,\n",
       " 0.0005940813571214676,\n",
       " 0.000608684029430151,\n",
       " 0.0007069091079756618,\n",
       " 0.0008163453894667327,\n",
       " 0.000863274559378624,\n",
       " 0.000971974222920835,\n",
       " 0.0010094080353155732,\n",
       " 0.0014781728386878967,\n",
       " 0.0010443396167829633,\n",
       " 0.0011781423818320036,\n",
       " 0.0011569905327633023,\n",
       " 0.0012199005577713251,\n",
       " 0.0014062381815165281,\n",
       " 0.001697532250545919,\n",
       " 0.0018726664129644632,\n",
       " 0.0024299840442836285,\n",
       " 0.0032644513994455338,\n",
       " 0.005052490625530481,\n",
       " 0.01282460056245327,\n",
       " 0.4363311231136322,\n",
       " 0.0005870854365639389,\n",
       " 0.0006681421655230224,\n",
       " 0.0007734778919257224,\n",
       " 0.0008136512478813529,\n",
       " 0.0009469621581956744,\n",
       " 0.0010026793461292982,\n",
       " 0.0014829294523224235,\n",
       " 0.0010246031451970339,\n",
       " 0.0011497996747493744,\n",
       " 0.0011474061757326126,\n",
       " 0.0011888861190527678,\n",
       " 0.0013846297515556216,\n",
       " 0.0016760419821366668,\n",
       " 0.0018369086319580674,\n",
       " 0.002409060951322317,\n",
       " 0.003259146586060524,\n",
       " 0.005057523958384991,\n",
       " 0.01275818981230259,\n",
       " 0.4362083971500397,\n",
       " 0.0007120656664483249,\n",
       " 0.0007845733198337257,\n",
       " 0.0008280834299512208,\n",
       " 0.0009747340227477252,\n",
       " 0.0010363361798226833,\n",
       " 0.0014741065679118037,\n",
       " 0.0010617857333272696,\n",
       " 0.001197352074086666,\n",
       " 0.0011659322772175074,\n",
       " 0.0012234619352966547,\n",
       " 0.0014162739971652627,\n",
       " 0.0017053488409146667,\n",
       " 0.0018446880858391523,\n",
       " 0.002443774836137891,\n",
       " 0.0033005450386554003,\n",
       " 0.005038026254624128,\n",
       " 0.012859955430030823,\n",
       " 0.4363422393798828,\n",
       " 0.0009452129015699029,\n",
       " 0.0009330610046163201,\n",
       " 0.0010520836804062128,\n",
       " 0.0011165810283273458,\n",
       " 0.00157647836022079,\n",
       " 0.001154333003796637,\n",
       " 0.0012762666447088122,\n",
       " 0.0012705691624432802,\n",
       " 0.0013171187601983547,\n",
       " 0.0015087706269696355,\n",
       " 0.0018002584110945463,\n",
       " 0.0019503496587276459,\n",
       " 0.002527795732021332,\n",
       " 0.003395772073417902,\n",
       " 0.005127783864736557,\n",
       " 0.012982597574591637,\n",
       " 0.43669748306274414,\n",
       " 0.001107578631490469,\n",
       " 0.0011745786760002375,\n",
       " 0.0012356009101495147,\n",
       " 0.0016782935708761215,\n",
       " 0.001245747203938663,\n",
       " 0.001406002091243863,\n",
       " 0.0013764041941612959,\n",
       " 0.0014300288166850805,\n",
       " 0.0016293175285682082,\n",
       " 0.001935335574671626,\n",
       " 0.002068552654236555,\n",
       " 0.0026446315459907055,\n",
       " 0.0035025556571781635,\n",
       " 0.005233290605247021,\n",
       " 0.013107928447425365,\n",
       " 0.43669503927230835,\n",
       " 0.001292530563659966,\n",
       " 0.0012599598849192262,\n",
       " 0.0017173998057842255,\n",
       " 0.0012825484154745936,\n",
       " 0.0014242641627788544,\n",
       " 0.0014261192409321666,\n",
       " 0.001450238865800202,\n",
       " 0.0016441307961940765,\n",
       " 0.0019452327396720648,\n",
       " 0.0020906913559883833,\n",
       " 0.002690125722438097,\n",
       " 0.0035159133840352297,\n",
       " 0.0052772508934140205,\n",
       " 0.01313546858727932,\n",
       " 0.4372224807739258,\n",
       " 0.0014632109086960554,\n",
       " 0.0018602346535772085,\n",
       " 0.0014082819689065218,\n",
       " 0.0015406118473038077,\n",
       " 0.0015111221000552177,\n",
       " 0.0015520796878263354,\n",
       " 0.0017768429825082421,\n",
       " 0.002066598739475012,\n",
       " 0.0021969503723084927,\n",
       " 0.0027974701952189207,\n",
       " 0.003626408753916621,\n",
       " 0.0053892964497208595,\n",
       " 0.013315707445144653,\n",
       " 0.43784403800964355,\n",
       " 0.00195852923206985,\n",
       " 0.0014506492298096418,\n",
       " 0.001544116297736764,\n",
       " 0.0015651568537577987,\n",
       " 0.0016155469929799438,\n",
       " 0.0018077681306749582,\n",
       " 0.002108930144459009,\n",
       " 0.0022596046328544617,\n",
       " 0.002843606285750866,\n",
       " 0.0036529842764139175,\n",
       " 0.0054449886083602905,\n",
       " 0.013351249508559704,\n",
       " 0.43763524293899536,\n",
       " 0.0020214819815009832,\n",
       " 0.002195012755692005,\n",
       " 0.002061939099803567,\n",
       " 0.0020760444458574057,\n",
       " 0.0022775845136493444,\n",
       " 0.0025578767526894808,\n",
       " 0.0026767216622829437,\n",
       " 0.003263533115386963,\n",
       " 0.004097169730812311,\n",
       " 0.005881441291421652,\n",
       " 0.013756224885582924,\n",
       " 0.43868082761764526,\n",
       " 0.001642165007069707,\n",
       " 0.0016249961918219924,\n",
       " 0.0016228925669565797,\n",
       " 0.0018312737811356783,\n",
       " 0.0021483523305505514,\n",
       " 0.0022872770205140114,\n",
       " 0.002897216472774744,\n",
       " 0.0037018198054283857,\n",
       " 0.005474546458572149,\n",
       " 0.013285214081406593,\n",
       " 0.4372653067111969,\n",
       " 0.0017588777700439095,\n",
       " 0.0017442737007513642,\n",
       " 0.001959872432053089,\n",
       " 0.0022591627202928066,\n",
       " 0.002382283564656973,\n",
       " 0.002980562625452876,\n",
       " 0.00377918710000813,\n",
       " 0.005605102516710758,\n",
       " 0.013435659930109978,\n",
       " 0.4376177191734314,\n",
       " 0.00173871626611799,\n",
       " 0.0018749848240986466,\n",
       " 0.0022175940684974194,\n",
       " 0.002337138867005706,\n",
       " 0.0029413707088679075,\n",
       " 0.003760309424251318,\n",
       " 0.005518722347915173,\n",
       " 0.013575834222137928,\n",
       " 0.43816909193992615,\n",
       " 0.0019207398872822523,\n",
       " 0.0022356673143804073,\n",
       " 0.0023556817322969437,\n",
       " 0.0030141689348965883,\n",
       " 0.0037845312617719173,\n",
       " 0.005559500306844711,\n",
       " 0.013578049838542938,\n",
       " 0.4382080137729645,\n",
       " 0.0024221688508987427,\n",
       " 0.0025349357165396214,\n",
       " 0.0030859210528433323,\n",
       " 0.003931296523660421,\n",
       " 0.005806636996567249,\n",
       " 0.01393259596079588,\n",
       " 0.438743531703949,\n",
       " 0.0028797918930649757,\n",
       " 0.0034834519028663635,\n",
       " 0.004218758083879948,\n",
       " 0.00611159298568964,\n",
       " 0.014023026451468468,\n",
       " 0.4384180009365082,\n",
       " 0.003521127160638571,\n",
       " 0.004310331307351589,\n",
       " 0.0061722747050225735,\n",
       " 0.014408069662749767,\n",
       " 0.4396587014198303,\n",
       " 0.00466908561065793,\n",
       " 0.006575433071702719,\n",
       " 0.014816904440522194,\n",
       " 0.4395374655723572,\n",
       " 0.007492288947105408,\n",
       " 0.015274330973625183,\n",
       " 0.4403708875179291,\n",
       " 0.015417994931340218,\n",
       " 0.44194936752319336,\n",
       " 0.43409353494644165]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kl_divergences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a85e75c6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
